{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: ipython in /Users/c.nies/Library/Python/3.9/lib/python/site-packages (8.18.1)\n","Collecting jupyter\n","  Downloading jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n","Collecting numpy\n","  Downloading numpy-2.0.2-cp39-cp39-macosx_14_0_arm64.whl (5.3 MB)\n","\u001b[K     |████████████████████████████████| 5.3 MB 3.5 MB/s eta 0:00:01\n","\u001b[?25hCollecting pandas\n","  Downloading pandas-2.2.3-cp39-cp39-macosx_11_0_arm64.whl (11.3 MB)\n","\u001b[K     |████████████████████████████████| 11.3 MB 6.3 MB/s eta 0:00:011\n","\u001b[?25hCollecting scikit-learn\n","  Downloading scikit_learn-1.5.2-cp39-cp39-macosx_12_0_arm64.whl (11.0 MB)\n","\u001b[K     |████████████████████████████████| 11.0 MB 12.0 MB/s eta 0:00:01\n","\u001b[?25hCollecting sklearn\n","  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n","\u001b[31m    ERROR: Command errored out with exit status 1:\n","     command: /Library/Developer/CommandLineTools/usr/bin/python3 -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/40/2jhlvjdd469f3j_8ngbzzz9c0000gn/T/pip-install-tdw736yu/sklearn_e5dbb68658a847aba5683fedaabc5160/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/40/2jhlvjdd469f3j_8ngbzzz9c0000gn/T/pip-install-tdw736yu/sklearn_e5dbb68658a847aba5683fedaabc5160/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /private/var/folders/40/2jhlvjdd469f3j_8ngbzzz9c0000gn/T/pip-pip-egg-info-jqbebjyw\n","         cwd: /private/var/folders/40/2jhlvjdd469f3j_8ngbzzz9c0000gn/T/pip-install-tdw736yu/sklearn_e5dbb68658a847aba5683fedaabc5160/\n","    Complete output (15 lines):\n","    The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n","    rather than 'sklearn' for pip commands.\n","    \n","    Here is how to fix this error in the main use cases:\n","    - use 'pip install scikit-learn' rather than 'pip install sklearn'\n","    - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n","      (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n","    - if the 'sklearn' package is used by one of your dependencies,\n","      it would be great if you take some time to track which package uses\n","      'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n","    - as a last resort, set the environment variable\n","      SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n","    \n","    More information is available at\n","    https://github.com/scikit-learn/sklearn-pypi-package\n","    ----------------------------------------\u001b[0m\n","\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/46/1c/395a83ee7b2d2ad7a05b453872053d41449564477c81dc356f720b16eac4/sklearn-0.0.post12.tar.gz#sha256=54cff9e20839b7b202321178228af4d9388bedf78425d9299fd9ee170d68802e (from https://pypi.org/simple/sklearn/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n","  Downloading sklearn-0.0.post11.tar.gz (3.6 kB)\n","\u001b[31m    ERROR: Command errored out with exit status 1:\n","     command: /Library/Developer/CommandLineTools/usr/bin/python3 -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/40/2jhlvjdd469f3j_8ngbzzz9c0000gn/T/pip-install-tdw736yu/sklearn_95f0703c03414189aad3eea1c595c16d/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/40/2jhlvjdd469f3j_8ngbzzz9c0000gn/T/pip-install-tdw736yu/sklearn_95f0703c03414189aad3eea1c595c16d/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /private/var/folders/40/2jhlvjdd469f3j_8ngbzzz9c0000gn/T/pip-pip-egg-info-efu5fsz1\n","         cwd: /private/var/folders/40/2jhlvjdd469f3j_8ngbzzz9c0000gn/T/pip-install-tdw736yu/sklearn_95f0703c03414189aad3eea1c595c16d/\n","    Complete output (18 lines):\n","    The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n","    rather than 'sklearn' for pip commands.\n","    \n","    Here is how to fix this error in the main use cases:\n","    - use 'pip install scikit-learn' rather than 'pip install sklearn'\n","    - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n","      (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n","    - if the 'sklearn' package is used by one of your dependencies,\n","      it would be great if you take some time to track which package uses\n","      'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n","    - as a last resort, set the environment variable\n","      SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n","    \n","    More information is available at\n","    https://github.com/scikit-learn/sklearn-pypi-package\n","    \n","    If the previous advice does not cover your use case, feel free to report it at\n","    https://github.com/scikit-learn/sklearn-pypi-package/issues/new\n","    ----------------------------------------\u001b[0m\n","\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/a4/0b/d1c703256cf293be77b7db44dbef62251fe02a97d0bef981f7120b0b0c0f/sklearn-0.0.post11.tar.gz#sha256=af035c4f0b970b7fc2d3856079aa1aa1032df3d7f65048a9d87114abf13c4629 (from https://pypi.org/simple/sklearn/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n","  Downloading sklearn-0.0.post10.tar.gz (3.6 kB)\n","\u001b[31m    ERROR: Command errored out with exit status 1:\n","     command: /Library/Developer/CommandLineTools/usr/bin/python3 -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/40/2jhlvjdd469f3j_8ngbzzz9c0000gn/T/pip-install-tdw736yu/sklearn_034cc2eee5644e4bb2ee020a11306ac8/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/40/2jhlvjdd469f3j_8ngbzzz9c0000gn/T/pip-install-tdw736yu/sklearn_034cc2eee5644e4bb2ee020a11306ac8/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /private/var/folders/40/2jhlvjdd469f3j_8ngbzzz9c0000gn/T/pip-pip-egg-info-bgt126t8\n","         cwd: /private/var/folders/40/2jhlvjdd469f3j_8ngbzzz9c0000gn/T/pip-install-tdw736yu/sklearn_034cc2eee5644e4bb2ee020a11306ac8/\n","    Complete output (18 lines):\n","    The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n","    rather than 'sklearn' for pip commands.\n","    \n","    Here is how to fix this error in the main use cases:\n","    - use 'pip install scikit-learn' rather than 'pip install sklearn'\n","    - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n","      (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n","    - if the 'sklearn' package is used by one of your dependencies,\n","      it would be great if you take some time to track which package uses\n","      'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n","    - as a last resort, set the environment variable\n","      SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n","    \n","    More information is available at\n","    https://github.com/scikit-learn/sklearn-pypi-package\n","    \n","    If the previous advice does not cover your use case, feel free to report it at\n","    https://github.com/scikit-learn/sklearn-pypi-package/issues/new\n","    ----------------------------------------\u001b[0m\n","\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/b9/0e/b2a4cfaa9e12b9ca4c71507bc26d2c99d75de172c0088c9835a98cf146ff/sklearn-0.0.post10.tar.gz#sha256=d4cd5a2e64b3caaf82cd5e33c46884dfeec5ebf991710d9faeb4fe81cadb3ba6 (from https://pypi.org/simple/sklearn/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n","  Downloading sklearn-0.0.post9.tar.gz (3.6 kB)\n","\u001b[31m    ERROR: Command errored out with exit status 1:\n","     command: /Library/Developer/CommandLineTools/usr/bin/python3 -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/40/2jhlvjdd469f3j_8ngbzzz9c0000gn/T/pip-install-tdw736yu/sklearn_fea11e767d154af6955e838cbea317bc/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/40/2jhlvjdd469f3j_8ngbzzz9c0000gn/T/pip-install-tdw736yu/sklearn_fea11e767d154af6955e838cbea317bc/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /private/var/folders/40/2jhlvjdd469f3j_8ngbzzz9c0000gn/T/pip-pip-egg-info-euouzqdm\n","         cwd: /private/var/folders/40/2jhlvjdd469f3j_8ngbzzz9c0000gn/T/pip-install-tdw736yu/sklearn_fea11e767d154af6955e838cbea317bc/\n","    Complete output (18 lines):\n","    The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n","    rather than 'sklearn' for pip commands.\n","    \n","    Here is how to fix this error in the main use cases:\n","    - use 'pip install scikit-learn' rather than 'pip install sklearn'\n","    - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n","      (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n","    - if the 'sklearn' package is used by one of your dependencies,\n","      it would be great if you take some time to track which package uses\n","      'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n","    - as a last resort, set the environment variable\n","      SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n","    \n","    More information is available at\n","    https://github.com/scikit-learn/sklearn-pypi-package\n","    \n","    If the previous advice does not cover your use case, feel free to report it at\n","    https://github.com/scikit-learn/sklearn-pypi-package/issues/new\n","    ----------------------------------------\u001b[0m\n","\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/28/86/207a003339023247fef1bb5bc9f5093140d17294b2f6d15bfcd4885e469e/sklearn-0.0.post9.tar.gz#sha256=1ff5864cf30489ee48a014fe8f4320d7bb59592392a4ef52ae9d7a37942615ac (from https://pypi.org/simple/sklearn/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n","  Downloading sklearn-0.0.post7.tar.gz (3.6 kB)\n","\u001b[31m    ERROR: Command errored out with exit status 1:\n","     command: /Library/Developer/CommandLineTools/usr/bin/python3 -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/40/2jhlvjdd469f3j_8ngbzzz9c0000gn/T/pip-install-tdw736yu/sklearn_9c43ff8abcdf487fa1f17beea77c90df/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/40/2jhlvjdd469f3j_8ngbzzz9c0000gn/T/pip-install-tdw736yu/sklearn_9c43ff8abcdf487fa1f17beea77c90df/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /private/var/folders/40/2jhlvjdd469f3j_8ngbzzz9c0000gn/T/pip-pip-egg-info-uquo0jzg\n","         cwd: /private/var/folders/40/2jhlvjdd469f3j_8ngbzzz9c0000gn/T/pip-install-tdw736yu/sklearn_9c43ff8abcdf487fa1f17beea77c90df/\n","    Complete output (18 lines):\n","    The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n","    rather than 'sklearn' for pip commands.\n","    \n","    Here is how to fix this error in the main use cases:\n","    - use 'pip install scikit-learn' rather than 'pip install sklearn'\n","    - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n","      (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n","    - if the 'sklearn' package is used by one of your dependencies,\n","      it would be great if you take some time to track which package uses\n","      'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n","    - as a last resort, set the environment variable\n","      SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n","    \n","    More information is available at\n","    https://github.com/scikit-learn/sklearn-pypi-package\n","    \n","    If the previous advice does not cover your use case, feel free to report it at\n","    https://github.com/scikit-learn/sklearn-pypi-package/issues/new\n","    ----------------------------------------\u001b[0m\n","\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/70/ce/81aa643f3c43488c4a1e417e45f696a61e7ac82b57190fad3c310df2c07b/sklearn-0.0.post7.tar.gz#sha256=1c89020b364fdc3aa2839e0ae34e8f0b406669e4b5c2359dda3ac398f9c76874 (from https://pypi.org/simple/sklearn/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n","  Downloading sklearn-0.0.post5.tar.gz (3.7 kB)\n","\u001b[31m    ERROR: Command errored out with exit status 1:\n","     command: /Library/Developer/CommandLineTools/usr/bin/python3 -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/40/2jhlvjdd469f3j_8ngbzzz9c0000gn/T/pip-install-tdw736yu/sklearn_314fafdab6f140329ba6c0b65a3ac6cf/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/40/2jhlvjdd469f3j_8ngbzzz9c0000gn/T/pip-install-tdw736yu/sklearn_314fafdab6f140329ba6c0b65a3ac6cf/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /private/var/folders/40/2jhlvjdd469f3j_8ngbzzz9c0000gn/T/pip-pip-egg-info-lz2sxkpc\n","         cwd: /private/var/folders/40/2jhlvjdd469f3j_8ngbzzz9c0000gn/T/pip-install-tdw736yu/sklearn_314fafdab6f140329ba6c0b65a3ac6cf/\n","    Complete output (18 lines):\n","    The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n","    rather than 'sklearn' for pip commands.\n","    \n","    Here is how to fix this error in the main use cases:\n","    - use 'pip install scikit-learn' rather than 'pip install sklearn'\n","    - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n","      (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n","    - if the 'sklearn' package is used by one of your dependencies,\n","      it would be great if you take some time to track which package uses\n","      'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n","    - as a last resort, set the environment variable\n","      SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n","    \n","    More information is available at\n","    https://github.com/scikit-learn/sklearn-pypi-package\n","    \n","    If the previous advice does not cover your use case, feel free to report it at\n","    https://github.com/scikit-learn/sklearn-pypi-package/issues/new\n","    ----------------------------------------\u001b[0m\n","\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/7a/93/e0e1b1e98f39dfca7ec9795cb46f6e09e88a2fd5d4a28e4b3d1f618a2aec/sklearn-0.0.post5.tar.gz#sha256=7377c714a03a79bbe9196f435db931fd2a6fa8c68514da7ed3a251fd08c52e2c (from https://pypi.org/simple/sklearn/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n","  Downloading sklearn-0.0.post4.tar.gz (3.6 kB)\n","\u001b[31m    ERROR: Command errored out with exit status 1:\n","     command: /Library/Developer/CommandLineTools/usr/bin/python3 -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/40/2jhlvjdd469f3j_8ngbzzz9c0000gn/T/pip-install-tdw736yu/sklearn_b4d12abac9c24970b5bd6d90d48ca3a0/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/40/2jhlvjdd469f3j_8ngbzzz9c0000gn/T/pip-install-tdw736yu/sklearn_b4d12abac9c24970b5bd6d90d48ca3a0/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /private/var/folders/40/2jhlvjdd469f3j_8ngbzzz9c0000gn/T/pip-pip-egg-info-82x61ix9\n","         cwd: /private/var/folders/40/2jhlvjdd469f3j_8ngbzzz9c0000gn/T/pip-install-tdw736yu/sklearn_b4d12abac9c24970b5bd6d90d48ca3a0/\n","    Complete output (18 lines):\n","    The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n","    rather than 'sklearn' for pip commands.\n","    \n","    Here is how to fix this error in the main use cases:\n","    - use 'pip install scikit-learn' rather than 'pip install sklearn'\n","    - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n","      (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n","    - if the 'sklearn' package is used by one of your dependencies,\n","      it would be great if you take some time to track which package uses\n","      'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n","    - as a last resort, set the environment variable\n","      SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n","    \n","    More information is available at\n","    https://github.com/scikit-learn/sklearn-pypi-package\n","    \n","    If the previous advice does not cover your use case, feel free to report it at\n","    https://github.com/scikit-learn/sklearn-pypi-package/issues/new\n","    ----------------------------------------\u001b[0m\n","\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/99/b2/165110013aa66fae6fc13918ad0e9de4801e5f1691d371bf8b63328037e6/sklearn-0.0.post4.tar.gz#sha256=0e81ec9c32d4bb418e7be8f1ec1027d174975502dc84cbc4f4564b4cba31e674 (from https://pypi.org/simple/sklearn/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n","  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n","\u001b[31m    ERROR: Command errored out with exit status 1:\n","     command: /Library/Developer/CommandLineTools/usr/bin/python3 -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/40/2jhlvjdd469f3j_8ngbzzz9c0000gn/T/pip-install-tdw736yu/sklearn_ab9b843678f743a4acdeace5678b928b/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/40/2jhlvjdd469f3j_8ngbzzz9c0000gn/T/pip-install-tdw736yu/sklearn_ab9b843678f743a4acdeace5678b928b/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /private/var/folders/40/2jhlvjdd469f3j_8ngbzzz9c0000gn/T/pip-pip-egg-info-l6lmapbk\n","         cwd: /private/var/folders/40/2jhlvjdd469f3j_8ngbzzz9c0000gn/T/pip-install-tdw736yu/sklearn_ab9b843678f743a4acdeace5678b928b/\n","    Complete output (18 lines):\n","    The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n","    rather than 'sklearn' for pip commands.\n","    \n","    Here is how to fix this error in the main use cases:\n","    - use 'pip install scikit-learn' rather than 'pip install sklearn'\n","    - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n","      (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n","    - if the 'sklearn' package is used by one of your dependencies,\n","      it would be great if you take some time to track which package uses\n","      'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n","    - as a last resort, set the environment variable\n","      SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n","    \n","    More information is available at\n","    https://github.com/scikit-learn/sklearn-pypi-package\n","    \n","    If the previous advice does not cover your use case, feel free to report it at\n","    https://github.com/scikit-learn/sklearn-pypi-package/issues/new\n","    ----------------------------------------\u001b[0m\n","\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/db/1e/af4e9cded5093a92e60d4ae7149a02c7427661b2db66c8ea4d34b17864a2/sklearn-0.0.post1.tar.gz#sha256=76b9ed1623775168657b86b5fe966d45752e5c87f528de6240c38923b94147c5 (from https://pypi.org/simple/sklearn/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n","  Downloading sklearn-0.0.tar.gz (1.1 kB)\n","Collecting keras\n","  Downloading keras-3.6.0-py3-none-any.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 12.5 MB/s eta 0:00:01\n","\u001b[?25hCollecting tensorflow\n","  Downloading tensorflow-2.17.0-cp39-cp39-macosx_12_0_arm64.whl (236.1 MB)\n","\u001b[K     |████████████████████████████████| 236.1 MB 10.5 MB/s eta 0:00:01\n","\u001b[?25hCollecting matplotlib\n","  Downloading matplotlib-3.9.2-cp39-cp39-macosx_11_0_arm64.whl (7.8 MB)\n","\u001b[K     |████████████████████████████████| 7.8 MB 11.1 MB/s eta 0:00:01\n","\u001b[?25hRequirement already satisfied: matplotlib-inline in /Users/c.nies/Library/Python/3.9/lib/python/site-packages (from ipython) (0.1.7)\n","Requirement already satisfied: stack-data in /Users/c.nies/Library/Python/3.9/lib/python/site-packages (from ipython) (0.6.3)\n","Requirement already satisfied: typing-extensions in /Users/c.nies/Library/Python/3.9/lib/python/site-packages (from ipython) (4.12.2)\n","Requirement already satisfied: exceptiongroup in /Users/c.nies/Library/Python/3.9/lib/python/site-packages (from ipython) (1.2.2)\n","Requirement already satisfied: pygments>=2.4.0 in /Users/c.nies/Library/Python/3.9/lib/python/site-packages (from ipython) (2.18.0)\n","Requirement already satisfied: pexpect>4.3 in /Users/c.nies/Library/Python/3.9/lib/python/site-packages (from ipython) (4.9.0)\n","Requirement already satisfied: traitlets>=5 in /Users/c.nies/Library/Python/3.9/lib/python/site-packages (from ipython) (5.14.3)\n","Requirement already satisfied: decorator in /Users/c.nies/Library/Python/3.9/lib/python/site-packages (from ipython) (5.1.1)\n","Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /Users/c.nies/Library/Python/3.9/lib/python/site-packages (from ipython) (3.0.48)\n","Requirement already satisfied: jedi>=0.16 in /Users/c.nies/Library/Python/3.9/lib/python/site-packages (from ipython) (0.19.1)\n","Requirement already satisfied: ipykernel in /Users/c.nies/Library/Python/3.9/lib/python/site-packages (from jupyter) (6.29.5)\n","Collecting jupyterlab\n","  Downloading jupyterlab-4.2.5-py3-none-any.whl (11.6 MB)\n","\u001b[K     |████████████████████████████████| 11.6 MB 9.8 MB/s eta 0:00:011\n","\u001b[?25hCollecting nbconvert\n","  Downloading nbconvert-7.16.4-py3-none-any.whl (257 kB)\n","\u001b[K     |████████████████████████████████| 257 kB 12.0 MB/s eta 0:00:01\n","\u001b[?25hCollecting jupyter-console\n","  Downloading jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n","Collecting ipywidgets\n","  Downloading ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n","\u001b[K     |████████████████████████████████| 139 kB 8.9 MB/s eta 0:00:01\n","\u001b[?25hCollecting notebook\n","  Downloading notebook-7.2.2-py3-none-any.whl (5.0 MB)\n","\u001b[K     |████████████████████████████████| 5.0 MB 6.6 MB/s eta 0:00:01\n","\u001b[?25hCollecting pytz>=2020.1\n","  Downloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n","\u001b[K     |████████████████████████████████| 508 kB 12.5 MB/s eta 0:00:01\n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /Users/c.nies/Library/Python/3.9/lib/python/site-packages (from pandas) (2.9.0.post0)\n","Collecting tzdata>=2022.7\n","  Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n","\u001b[K     |████████████████████████████████| 346 kB 12.7 MB/s eta 0:00:01\n","\u001b[?25hCollecting threadpoolctl>=3.1.0\n","  Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n","Collecting joblib>=1.2.0\n","  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n","\u001b[K     |████████████████████████████████| 301 kB 11.1 MB/s eta 0:00:01\n","\u001b[?25hCollecting scipy>=1.6.0\n","  Downloading scipy-1.13.1-cp39-cp39-macosx_12_0_arm64.whl (30.3 MB)\n","\u001b[K     |████████████████████████████████| 30.3 MB 11.8 MB/s eta 0:00:01\n","\u001b[?25hCollecting rich\n","  Downloading rich-13.9.2-py3-none-any.whl (242 kB)\n","\u001b[K     |████████████████████████████████| 242 kB 5.8 MB/s eta 0:00:01\n","\u001b[?25hCollecting ml-dtypes\n","  Downloading ml_dtypes-0.5.0-cp39-cp39-macosx_10_9_universal2.whl (732 kB)\n","\u001b[K     |████████████████████████████████| 732 kB 6.8 MB/s eta 0:00:01\n","\u001b[?25hCollecting optree\n","  Downloading optree-0.13.0-cp39-cp39-macosx_11_0_arm64.whl (296 kB)\n","\u001b[K     |████████████████████████████████| 296 kB 11.6 MB/s eta 0:00:01\n","\u001b[?25hCollecting h5py\n","  Downloading h5py-3.12.1-cp39-cp39-macosx_11_0_arm64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 13.8 MB/s eta 0:00:01\n","\u001b[?25hCollecting absl-py\n","  Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n","\u001b[K     |████████████████████████████████| 133 kB 9.4 MB/s eta 0:00:01\n","\u001b[?25hRequirement already satisfied: packaging in /Users/c.nies/Library/Python/3.9/lib/python/site-packages (from keras) (24.1)\n","Collecting namex\n","  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n","Collecting ml-dtypes\n","  Downloading ml_dtypes-0.4.1-cp39-cp39-macosx_10_9_universal2.whl (396 kB)\n","\u001b[K     |████████████████████████████████| 396 kB 8.2 MB/s eta 0:00:01\n","\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n","  Downloading grpcio-1.66.2-cp39-cp39-macosx_10_9_universal2.whl (10.8 MB)\n","\u001b[K     |████████████████████████████████| 10.8 MB 8.3 MB/s eta 0:00:01\n","\u001b[?25hCollecting google-pasta>=0.1.1\n","  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n","\u001b[K     |████████████████████████████████| 57 kB 12.8 MB/s eta 0:00:01\n","\u001b[?25hCollecting libclang>=13.0.0\n","  Downloading libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl (25.8 MB)\n","\u001b[K     |████████████████████████████████| 25.8 MB 10.1 MB/s eta 0:00:01\n","\u001b[?25hCollecting requests<3,>=2.21.0\n","  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n","\u001b[K     |████████████████████████████████| 64 kB 8.4 MB/s  eta 0:00:01\n","\u001b[?25hCollecting opt-einsum>=2.3.2\n","  Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n","\u001b[K     |████████████████████████████████| 71 kB 1.5 MB/s  eta 0:00:01\n","\u001b[?25hCollecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n","  Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n","Collecting termcolor>=1.1.0\n","  Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n","Collecting numpy\n","  Downloading numpy-1.26.4-cp39-cp39-macosx_11_0_arm64.whl (14.0 MB)\n","\u001b[K     |████████████████████████████████| 14.0 MB 12.3 MB/s eta 0:00:01\n","\u001b[?25hRequirement already satisfied: six>=1.12.0 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (1.15.0)\n","Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n","  Downloading protobuf-4.25.5-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n","\u001b[K     |████████████████████████████████| 394 kB 10.4 MB/s eta 0:00:01\n","\u001b[?25hCollecting wrapt>=1.11.0\n","  Downloading wrapt-1.16.0-cp39-cp39-macosx_11_0_arm64.whl (38 kB)\n","Collecting tensorboard<2.18,>=2.17\n","  Downloading tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n","\u001b[K     |████████████████████████████████| 5.5 MB 13.1 MB/s eta 0:00:01\n","\u001b[?25hCollecting astunparse>=1.6.0\n","  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n","Collecting flatbuffers>=24.3.25\n","  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n","Collecting tensorflow-io-gcs-filesystem>=0.23.1\n","  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp39-cp39-macosx_12_0_arm64.whl (3.5 MB)\n","\u001b[K     |████████████████████████████████| 3.5 MB 14.1 MB/s eta 0:00:01\n","\u001b[?25hRequirement already satisfied: setuptools in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (58.0.4)\n","Collecting cycler>=0.10\n","  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n","Collecting contourpy>=1.0.1\n","  Downloading contourpy-1.3.0-cp39-cp39-macosx_11_0_arm64.whl (249 kB)\n","\u001b[K     |████████████████████████████████| 249 kB 10.5 MB/s eta 0:00:01\n","\u001b[?25hCollecting fonttools>=4.22.0\n","  Downloading fonttools-4.54.1-cp39-cp39-macosx_11_0_arm64.whl (2.3 MB)\n","\u001b[K     |████████████████████████████████| 2.3 MB 15.3 MB/s eta 0:00:01\n","\u001b[?25hCollecting kiwisolver>=1.3.1\n","  Downloading kiwisolver-1.4.7-cp39-cp39-macosx_11_0_arm64.whl (64 kB)\n","\u001b[K     |████████████████████████████████| 64 kB 7.7 MB/s  eta 0:00:01\n","\u001b[?25hCollecting pyparsing>=2.3.1\n","  Downloading pyparsing-3.1.4-py3-none-any.whl (104 kB)\n","\u001b[K     |████████████████████████████████| 104 kB 11.9 MB/s eta 0:00:01\n","\u001b[?25hCollecting pillow>=8\n","  Downloading pillow-10.4.0-cp39-cp39-macosx_11_0_arm64.whl (3.4 MB)\n","\u001b[K     |████████████████████████████████| 3.4 MB 13.2 MB/s eta 0:00:01\n","\u001b[?25hCollecting importlib-resources>=3.2.0\n","  Downloading importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n","Requirement already satisfied: zipp>=3.1.0 in /Users/c.nies/Library/Python/3.9/lib/python/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.20.2)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in /Users/c.nies/Library/Python/3.9/lib/python/site-packages (from jedi>=0.16->ipython) (0.8.4)\n","Requirement already satisfied: ptyprocess>=0.5 in /Users/c.nies/Library/Python/3.9/lib/python/site-packages (from pexpect>4.3->ipython) (0.7.0)\n","Requirement already satisfied: wcwidth in /Users/c.nies/Library/Python/3.9/lib/python/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython) (0.2.13)\n","Collecting urllib3<3,>=1.21.1\n","  Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n","\u001b[K     |████████████████████████████████| 126 kB 2.0 MB/s eta 0:00:01\n","\u001b[?25hCollecting idna<4,>=2.5\n","  Downloading idna-3.10-py3-none-any.whl (70 kB)\n","\u001b[K     |████████████████████████████████| 70 kB 3.5 MB/s eta 0:00:01\n","\u001b[?25hCollecting charset-normalizer<4,>=2\n","  Downloading charset_normalizer-3.3.2-cp39-cp39-macosx_11_0_arm64.whl (120 kB)\n","\u001b[K     |████████████████████████████████| 120 kB 3.2 MB/s eta 0:00:01\n","\u001b[?25hCollecting certifi>=2017.4.17\n","  Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n","\u001b[K     |████████████████████████████████| 167 kB 3.7 MB/s eta 0:00:01\n","\u001b[?25hCollecting tensorboard-data-server<0.8.0,>=0.7.0\n","  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n","Collecting werkzeug>=1.0.1\n","  Downloading werkzeug-3.0.4-py3-none-any.whl (227 kB)\n","\u001b[K     |████████████████████████████████| 227 kB 3.9 MB/s eta 0:00:01\n","\u001b[?25hCollecting markdown>=2.6.8\n","  Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n","\u001b[K     |████████████████████████████████| 106 kB 3.9 MB/s eta 0:00:01\n","\u001b[?25hRequirement already satisfied: importlib-metadata>=4.4 in /Users/c.nies/Library/Python/3.9/lib/python/site-packages (from markdown>=2.6.8->tensorboard<2.18,>=2.17->tensorflow) (8.5.0)\n","Collecting MarkupSafe>=2.1.1\n","  Downloading MarkupSafe-2.1.5-cp39-cp39-macosx_10_9_universal2.whl (18 kB)\n","Requirement already satisfied: psutil in /Users/c.nies/Library/Python/3.9/lib/python/site-packages (from ipykernel->jupyter) (6.0.0)\n","Requirement already satisfied: jupyter-client>=6.1.12 in /Users/c.nies/Library/Python/3.9/lib/python/site-packages (from ipykernel->jupyter) (8.6.3)\n","Requirement already satisfied: pyzmq>=24 in /Users/c.nies/Library/Python/3.9/lib/python/site-packages (from ipykernel->jupyter) (26.2.0)\n","Requirement already satisfied: comm>=0.1.1 in /Users/c.nies/Library/Python/3.9/lib/python/site-packages (from ipykernel->jupyter) (0.2.2)\n","Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /Users/c.nies/Library/Python/3.9/lib/python/site-packages (from ipykernel->jupyter) (5.7.2)\n","Requirement already satisfied: appnope in /Users/c.nies/Library/Python/3.9/lib/python/site-packages (from ipykernel->jupyter) (0.1.4)\n","Requirement already satisfied: nest-asyncio in /Users/c.nies/Library/Python/3.9/lib/python/site-packages (from ipykernel->jupyter) (1.6.0)\n","Requirement already satisfied: tornado>=6.1 in /Users/c.nies/Library/Python/3.9/lib/python/site-packages (from ipykernel->jupyter) (6.4.1)\n","Requirement already satisfied: debugpy>=1.6.5 in /Users/c.nies/Library/Python/3.9/lib/python/site-packages (from ipykernel->jupyter) (1.8.6)\n","Requirement already satisfied: platformdirs>=2.5 in /Users/c.nies/Library/Python/3.9/lib/python/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (4.3.6)\n","Collecting jupyterlab-widgets~=3.0.12\n","  Downloading jupyterlab_widgets-3.0.13-py3-none-any.whl (214 kB)\n","\u001b[K     |████████████████████████████████| 214 kB 3.6 MB/s eta 0:00:01\n","\u001b[?25hCollecting widgetsnbextension~=4.0.12\n","  Downloading widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n","\u001b[K     |████████████████████████████████| 2.3 MB 3.7 MB/s eta 0:00:01\n","\u001b[?25hCollecting jupyterlab-server<3,>=2.27.1\n","  Downloading jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n","\u001b[K     |████████████████████████████████| 59 kB 6.3 MB/s eta 0:00:01\n","\u001b[?25hCollecting httpx>=0.25.0\n","  Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n","\u001b[K     |████████████████████████████████| 76 kB 6.1 MB/s eta 0:00:011\n","\u001b[?25hCollecting tomli>=1.2.2\n","  Downloading tomli-2.0.2-py3-none-any.whl (13 kB)\n","Collecting notebook-shim>=0.2\n","  Downloading notebook_shim-0.2.4-py3-none-any.whl (13 kB)\n","Collecting jupyter-lsp>=2.0.0\n","  Downloading jupyter_lsp-2.2.5-py3-none-any.whl (69 kB)\n","\u001b[K     |████████████████████████████████| 69 kB 6.7 MB/s eta 0:00:01\n","\u001b[?25hCollecting jinja2>=3.0.3\n","  Downloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n","\u001b[K     |████████████████████████████████| 133 kB 4.9 MB/s eta 0:00:01\n","\u001b[?25hCollecting jupyter-server<3,>=2.4.0\n","  Downloading jupyter_server-2.14.2-py3-none-any.whl (383 kB)\n","\u001b[K     |████████████████████████████████| 383 kB 4.5 MB/s eta 0:00:01\n","\u001b[?25hCollecting async-lru>=1.0.0\n","  Downloading async_lru-2.0.4-py3-none-any.whl (6.1 kB)\n","Collecting anyio\n","  Downloading anyio-4.6.0-py3-none-any.whl (89 kB)\n","\u001b[K     |████████████████████████████████| 89 kB 6.7 MB/s eta 0:00:011\n","\u001b[?25hCollecting httpcore==1.*\n","  Downloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n","\u001b[K     |████████████████████████████████| 78 kB 6.4 MB/s eta 0:00:01\n","\u001b[?25hCollecting sniffio\n","  Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n","Collecting h11<0.15,>=0.13\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[K     |████████████████████████████████| 58 kB 6.3 MB/s eta 0:00:011\n","\u001b[?25hCollecting jupyter-server-terminals>=0.4.4\n","  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n","Collecting overrides>=5.0\n","  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n","Collecting jupyter-events>=0.9.0\n","  Downloading jupyter_events-0.10.0-py3-none-any.whl (18 kB)\n","Collecting websocket-client>=1.7\n","  Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n","\u001b[K     |████████████████████████████████| 58 kB 5.6 MB/s eta 0:00:01\n","\u001b[?25hCollecting terminado>=0.8.3\n","  Downloading terminado-0.18.1-py3-none-any.whl (14 kB)\n","Collecting prometheus-client>=0.9\n","  Downloading prometheus_client-0.21.0-py3-none-any.whl (54 kB)\n","\u001b[K     |████████████████████████████████| 54 kB 6.8 MB/s eta 0:00:011\n","\u001b[?25hCollecting send2trash>=1.8.2\n","  Downloading Send2Trash-1.8.3-py3-none-any.whl (18 kB)\n","Collecting argon2-cffi>=21.1\n","  Downloading argon2_cffi-23.1.0-py3-none-any.whl (15 kB)\n","Collecting nbformat>=5.3.0\n","  Downloading nbformat-5.10.4-py3-none-any.whl (78 kB)\n","\u001b[K     |████████████████████████████████| 78 kB 7.6 MB/s eta 0:00:011\n","\u001b[?25hCollecting argon2-cffi-bindings\n","  Downloading argon2_cffi_bindings-21.2.0-cp38-abi3-macosx_10_9_universal2.whl (53 kB)\n","\u001b[K     |████████████████████████████████| 53 kB 5.3 MB/s eta 0:00:01\n","\u001b[?25hCollecting referencing\n","  Downloading referencing-0.35.1-py3-none-any.whl (26 kB)\n","Collecting jsonschema[format-nongpl]>=4.18.0\n","  Downloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\n","\u001b[K     |████████████████████████████████| 88 kB 5.6 MB/s eta 0:00:01\n","\u001b[?25hCollecting rfc3339-validator\n","  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n","Collecting rfc3986-validator>=0.1.1\n","  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n","Collecting python-json-logger>=2.0.4\n","  Downloading python_json_logger-2.0.7-py3-none-any.whl (8.1 kB)\n","Collecting pyyaml>=5.3\n","  Downloading PyYAML-6.0.2-cp39-cp39-macosx_11_0_arm64.whl (172 kB)\n","\u001b[K     |████████████████████████████████| 172 kB 4.9 MB/s eta 0:00:01\n","\u001b[?25hCollecting attrs>=22.2.0\n","  Downloading attrs-24.2.0-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 4.0 MB/s eta 0:00:01\n","\u001b[?25hCollecting jsonschema-specifications>=2023.03.6\n","  Downloading jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\n","Collecting rpds-py>=0.7.1\n","  Downloading rpds_py-0.20.0-cp39-cp39-macosx_11_0_arm64.whl (311 kB)\n","\u001b[K     |████████████████████████████████| 311 kB 5.5 MB/s eta 0:00:01\n","\u001b[?25hCollecting webcolors>=24.6.0\n","  Downloading webcolors-24.8.0-py3-none-any.whl (15 kB)\n","Collecting isoduration\n","  Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n","Collecting jsonpointer>1.13\n","  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n","Collecting fqdn\n","  Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n","Collecting uri-template\n","  Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n","Collecting babel>=2.10\n","  Downloading babel-2.16.0-py3-none-any.whl (9.6 MB)\n","\u001b[K     |████████████████████████████████| 9.6 MB 7.5 MB/s eta 0:00:01\n","\u001b[?25hCollecting json5>=0.9.0\n","  Downloading json5-0.9.25-py3-none-any.whl (30 kB)\n","Collecting beautifulsoup4\n","  Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n","\u001b[K     |████████████████████████████████| 147 kB 8.8 MB/s eta 0:00:01\n","\u001b[?25hCollecting bleach!=5.0.0\n","  Downloading bleach-6.1.0-py3-none-any.whl (162 kB)\n","\u001b[K     |████████████████████████████████| 162 kB 11.1 MB/s eta 0:00:01\n","\u001b[?25hCollecting defusedxml\n","  Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n","Collecting nbclient>=0.5.0\n","  Downloading nbclient-0.10.0-py3-none-any.whl (25 kB)\n","Collecting mistune<4,>=2.0.3\n","  Downloading mistune-3.0.2-py3-none-any.whl (47 kB)\n","\u001b[K     |████████████████████████████████| 47 kB 10.7 MB/s eta 0:00:01\n","\u001b[?25hCollecting jupyterlab-pygments\n","  Downloading jupyterlab_pygments-0.3.0-py3-none-any.whl (15 kB)\n","Collecting pandocfilters>=1.4.1\n","  Downloading pandocfilters-1.5.1-py2.py3-none-any.whl (8.7 kB)\n","Collecting tinycss2\n","  Downloading tinycss2-1.3.0-py3-none-any.whl (22 kB)\n","Collecting webencodings\n","  Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n","Collecting fastjsonschema>=2.15\n","  Downloading fastjsonschema-2.20.0-py3-none-any.whl (23 kB)\n","Collecting cffi>=1.0.1\n","  Downloading cffi-1.17.1-cp39-cp39-macosx_11_0_arm64.whl (178 kB)\n","\u001b[K     |████████████████████████████████| 178 kB 11.0 MB/s eta 0:00:01\n","\u001b[?25hCollecting pycparser\n","  Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n","\u001b[K     |████████████████████████████████| 117 kB 11.0 MB/s eta 0:00:01\n","\u001b[?25hCollecting soupsieve>1.2\n","  Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n","Collecting arrow>=0.15.0\n","  Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n","\u001b[K     |████████████████████████████████| 66 kB 8.2 MB/s  eta 0:00:01\n","\u001b[?25hCollecting types-python-dateutil>=2.8.10\n","  Downloading types_python_dateutil-2.9.0.20241003-py3-none-any.whl (9.7 kB)\n","Collecting markdown-it-py>=2.2.0\n","  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n","\u001b[K     |████████████████████████████████| 87 kB 8.8 MB/s  eta 0:00:01\n","\u001b[?25hCollecting mdurl~=0.1\n","  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n","Requirement already satisfied: asttokens>=2.1.0 in /Users/c.nies/Library/Python/3.9/lib/python/site-packages (from stack-data->ipython) (2.4.1)\n","Requirement already satisfied: executing>=1.2.0 in /Users/c.nies/Library/Python/3.9/lib/python/site-packages (from stack-data->ipython) (2.1.0)\n","Requirement already satisfied: pure-eval in /Users/c.nies/Library/Python/3.9/lib/python/site-packages (from stack-data->ipython) (0.2.3)\n","Building wheels for collected packages: sklearn\n","  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1309 sha256=0b005bebdb565a0af4e64e55a9ed63c6a9c8c0f482fe3ea99a210a7c52e23e73\n","  Stored in directory: /Users/c.nies/Library/Caches/pip/wheels/e4/7b/98/b6466d71b8d738a0c547008b9eb39bf8676d1ff6ca4b22af1c\n","Successfully built sklearn\n","Installing collected packages: rpds-py, attrs, referencing, types-python-dateutil, jsonschema-specifications, pycparser, jsonschema, fastjsonschema, arrow, webencodings, webcolors, uri-template, soupsieve, rfc3986-validator, rfc3339-validator, nbformat, MarkupSafe, jsonpointer, isoduration, idna, fqdn, cffi, tinycss2, terminado, sniffio, pyyaml, python-json-logger, pandocfilters, nbclient, mistune, jupyterlab-pygments, jinja2, defusedxml, bleach, beautifulsoup4, argon2-cffi-bindings, websocket-client, urllib3, send2trash, prometheus-client, overrides, nbconvert, jupyter-server-terminals, jupyter-events, h11, charset-normalizer, certifi, argon2-cffi, anyio, requests, mdurl, jupyter-server, json5, httpcore, babel, tomli, numpy, notebook-shim, markdown-it-py, jupyterlab-server, jupyter-lsp, httpx, async-lru, widgetsnbextension, werkzeug, threadpoolctl, tensorboard-data-server, scipy, rich, protobuf, optree, namex, ml-dtypes, markdown, jupyterlab-widgets, jupyterlab, joblib, h5py, grpcio, absl-py, wrapt, tzdata, termcolor, tensorflow-io-gcs-filesystem, tensorboard, scikit-learn, pytz, pyparsing, pillow, opt-einsum, notebook, libclang, kiwisolver, keras, jupyter-console, ipywidgets, importlib-resources, google-pasta, gast, fonttools, flatbuffers, cycler, contourpy, astunparse, tensorflow, sklearn, pandas, matplotlib, jupyter\n","Successfully installed MarkupSafe-2.1.5 absl-py-2.1.0 anyio-4.6.0 argon2-cffi-23.1.0 argon2-cffi-bindings-21.2.0 arrow-1.3.0 astunparse-1.6.3 async-lru-2.0.4 attrs-24.2.0 babel-2.16.0 beautifulsoup4-4.12.3 bleach-6.1.0 certifi-2024.8.30 cffi-1.17.1 charset-normalizer-3.3.2 contourpy-1.3.0 cycler-0.12.1 defusedxml-0.7.1 fastjsonschema-2.20.0 flatbuffers-24.3.25 fonttools-4.54.1 fqdn-1.5.1 gast-0.6.0 google-pasta-0.2.0 grpcio-1.66.2 h11-0.14.0 h5py-3.12.1 httpcore-1.0.6 httpx-0.27.2 idna-3.10 importlib-resources-6.4.5 ipywidgets-8.1.5 isoduration-20.11.0 jinja2-3.1.4 joblib-1.4.2 json5-0.9.25 jsonpointer-3.0.0 jsonschema-4.23.0 jsonschema-specifications-2023.12.1 jupyter-1.1.1 jupyter-console-6.6.3 jupyter-events-0.10.0 jupyter-lsp-2.2.5 jupyter-server-2.14.2 jupyter-server-terminals-0.5.3 jupyterlab-4.2.5 jupyterlab-pygments-0.3.0 jupyterlab-server-2.27.3 jupyterlab-widgets-3.0.13 keras-3.6.0 kiwisolver-1.4.7 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 matplotlib-3.9.2 mdurl-0.1.2 mistune-3.0.2 ml-dtypes-0.4.1 namex-0.0.8 nbclient-0.10.0 nbconvert-7.16.4 nbformat-5.10.4 notebook-7.2.2 notebook-shim-0.2.4 numpy-1.26.4 opt-einsum-3.4.0 optree-0.13.0 overrides-7.7.0 pandas-2.2.3 pandocfilters-1.5.1 pillow-10.4.0 prometheus-client-0.21.0 protobuf-4.25.5 pycparser-2.22 pyparsing-3.1.4 python-json-logger-2.0.7 pytz-2024.2 pyyaml-6.0.2 referencing-0.35.1 requests-2.32.3 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 rich-13.9.2 rpds-py-0.20.0 scikit-learn-1.5.2 scipy-1.13.1 send2trash-1.8.3 sklearn-0.0 sniffio-1.3.1 soupsieve-2.6 tensorboard-2.17.1 tensorboard-data-server-0.7.2 tensorflow-2.17.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-2.4.0 terminado-0.18.1 threadpoolctl-3.5.0 tinycss2-1.3.0 tomli-2.0.2 types-python-dateutil-2.9.0.20241003 tzdata-2024.2 uri-template-1.3.0 urllib3-2.2.3 webcolors-24.8.0 webencodings-0.5.1 websocket-client-1.8.0 werkzeug-3.0.4 widgetsnbextension-4.0.13 wrapt-1.16.0\n","\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.2 is available.\n","You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install ipython jupyter numpy pandas scikit-learn sklearn keras tensorflow matplotlib"]},{"cell_type":"markdown","metadata":{"id":"lvan0YzN1_9G"},"source":["Autoencoder"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1798,"status":"ok","timestamp":1711934249891,"user":{"displayName":"Hui Wen Nies","userId":"05887277120475105053"},"user_tz":-480},"id":"CiTikJTUNNvL","outputId":"f088ea8f-d58d-4d7a-9e80-c9074660bac4"},"outputs":[{"name":"stderr","output_type":"stream","text":["Matplotlib is building the font cache; this may take a moment.\n","/Users/c.nies/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n","\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n","\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n","\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n","\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n","[[[0.         0.         0.         0.00392157 0.         0.\n","   0.         0.19215687 0.53333336 0.85882354 0.84705883 0.89411765\n","   0.9254902  1.         1.         1.         1.         0.8509804\n","   0.84313726 0.99607843 0.90588236 0.627451   0.1764706  0.\n","   0.         0.         0.         0.        ]\n","  [0.         0.         0.         0.         0.         0.05490196\n","   0.6901961  0.87058824 0.8784314  0.83137256 0.79607844 0.7764706\n","   0.76862746 0.78431374 0.84313726 0.8        0.7921569  0.7882353\n","   0.7882353  0.7882353  0.81960785 0.85490197 0.8784314  0.6431373\n","   0.         0.         0.         0.        ]]\n","\n"," [[0.         0.         0.         0.         0.         0.\n","   0.         0.         0.04705882 0.39215687 0.83137256 0.8039216\n","   0.7254902  0.7019608  0.6784314  0.7294118  0.75686276 0.8666667\n","   0.5568628  0.33333334 0.         0.         0.         0.\n","   0.         0.         0.         0.        ]\n","  [0.         0.         0.         0.         0.         0.\n","   0.         0.         0.         0.33333334 0.29803923 0.78039217\n","   0.88235295 0.972549   1.         0.93333334 0.8862745  0.6156863\n","   0.26666668 0.3137255  0.         0.         0.         0.\n","   0.         0.         0.         0.        ]]]\n","[[[0.         0.         0.         0.         0.         0.\n","   0.         0.03137255 0.47058824 0.81960785 0.8862745  0.96862745\n","   0.92941177 1.         1.         1.         0.96862745 0.93333334\n","   0.92156863 0.6745098  0.28235295 0.         0.         0.\n","   0.         0.         0.         0.        ]\n","  [0.         0.         0.         0.         0.         0.\n","   0.5372549  0.9372549  0.9882353  0.9529412  0.91764706 0.8980392\n","   0.93333334 0.95686275 0.9647059  0.9411765  0.9019608  0.9098039\n","   0.9372549  0.972549   0.9843137  0.7607843  0.         0.\n","   0.         0.         0.         0.        ]]\n","\n"," [[0.         0.         0.         0.         0.         0.\n","   0.         0.         0.00784314 0.         0.76862746 1.\n","   1.         1.         0.94509804 0.9843137  1.         0.9607843\n","   1.         0.29803923 0.         0.         0.         0.\n","   0.         0.         0.         0.        ]\n","  [0.         0.         0.         0.         0.         0.\n","   0.         0.         0.         0.         0.9529412  0.92941177\n","   0.8509804  0.89411765 0.90588236 0.87058824 0.85490197 0.85882354\n","   1.         0.45490196 0.         0.         0.         0.\n","   0.         0.         0.         0.        ]]]\n"]}],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","\n","from sklearn.metrics import accuracy_score, precision_score, recall_score\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras import layers, losses\n","from tensorflow.keras.datasets import fashion_mnist\n","from tensorflow.keras.models import Model\n","\n","(x_train, _), (x_test, _) = fashion_mnist.load_data()\n","\n","x_train = x_train.astype('float32') / 255.\n","print (x_train[1:3,1:3])\n","x_test = x_test.astype('float32') / 255.\n","print (x_test[1:3,1:3])\n","\n","# print (x_train.shape)\n","# print (x_test.shape)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":98580,"status":"ok","timestamp":1711935105100,"user":{"displayName":"Hui Wen Nies","userId":"05887277120475105053"},"user_tz":-480},"id":"4wQuvYdm2CwI","outputId":"3df726ae-6b24-4cc4-dad8-bb3efea8886d"},"outputs":[{"name":"stdout","output_type":"stream","text":["(60000, 28, 28)\n","(10000, 28, 28)\n","Epoch 1/10\n","1875/1875 [==============================] - 11s 5ms/step - loss: 0.0239 - val_loss: 0.0134\n","Epoch 2/10\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0117 - val_loss: 0.0106\n","Epoch 3/10\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0101 - val_loss: 0.0098\n","Epoch 4/10\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0095 - val_loss: 0.0095\n","Epoch 5/10\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.0092 - val_loss: 0.0092\n","Epoch 6/10\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.0091 - val_loss: 0.0091\n","Epoch 7/10\n","1875/1875 [==============================] - 10s 5ms/step - loss: 0.0090 - val_loss: 0.0092\n","Epoch 8/10\n","1875/1875 [==============================] - 11s 6ms/step - loss: 0.0089 - val_loss: 0.0091\n","Epoch 9/10\n","1875/1875 [==============================] - 11s 6ms/step - loss: 0.0088 - val_loss: 0.0089\n","Epoch 10/10\n","1875/1875 [==============================] - 10s 5ms/step - loss: 0.0088 - val_loss: 0.0089\n","[[5.168745   2.1514525  3.2276251  ... 1.885102   2.444021   2.6210747 ]\n"," [1.9713292  2.4657254  0.         ... 3.133112   4.1949105  0.6466563 ]\n"," [4.9124     2.1473598  0.         ... 1.5863001  1.2076362  5.6366153 ]\n"," ...\n"," [3.0164914  2.7890673  0.         ... 0.99524057 0.9058191  1.7808266 ]\n"," [4.9196568  2.1684272  0.         ... 2.5173428  0.72082204 6.1998076 ]\n"," [3.107502   2.29032    1.6746919  ... 2.45963    1.6755481  2.1028206 ]]\n","[[[3.39836419e-07 2.65441429e-07 3.29666864e-06 ... 1.37342533e-06\n","   2.15806040e-07 2.48200394e-07]\n","  [3.63691811e-07 2.54971360e-06 1.20281829e-05 ... 4.19689517e-04\n","   4.20484808e-04 9.17930606e-07]\n","  [2.36195069e-06 1.65271842e-06 1.66576353e-06 ... 1.45518454e-04\n","   7.61718431e-04 5.00374939e-04]\n","  ...\n","  [1.35550770e-04 4.25180078e-05 6.27896079e-05 ... 1.12650014e-04\n","   2.53588310e-04 2.17541528e-04]\n","  [3.09263232e-05 1.24526368e-05 8.93766719e-06 ... 4.30288201e-05\n","   2.67717569e-05 2.07694073e-04]\n","  [7.62653656e-07 2.21987975e-05 5.19039859e-05 ... 1.55915288e-04\n","   2.40770489e-04 1.82357144e-05]]\n","\n"," [[1.08518101e-08 9.21787802e-09 4.45064245e-07 ... 5.38536469e-08\n","   1.17963914e-08 4.68324979e-09]\n","  [2.62890580e-08 6.87902457e-07 2.94876460e-04 ... 2.00099149e-03\n","   6.42856758e-04 8.43658512e-08]\n","  [1.52757352e-07 4.20917672e-07 1.88848964e-04 ... 4.94212518e-03\n","   1.63311942e-03 1.88067468e-04]\n","  ...\n","  [1.69262217e-04 1.29570399e-04 5.67824231e-04 ... 6.18093414e-03\n","   3.19522689e-04 1.38769188e-04]\n","  [3.74641022e-05 9.21917526e-05 1.20408053e-03 ... 1.16419839e-02\n","   1.89526138e-04 2.05528704e-04]\n","  [4.98421230e-07 3.74231331e-06 6.14916091e-04 ... 7.82846007e-03\n","   9.06214409e-05 9.21228002e-06]]\n","\n"," [[9.52580770e-09 2.55284860e-08 2.10409610e-07 ... 2.47193611e-07\n","   4.04102707e-09 7.68761854e-09]\n","  [1.16045861e-07 1.48464707e-07 8.09156063e-06 ... 1.43196451e-06\n","   1.60497552e-06 4.04278708e-08]\n","  [1.09080098e-07 1.15325385e-08 5.14678433e-08 ... 1.32999567e-05\n","   5.44186548e-07 4.00619456e-06]\n","  ...\n","  [5.13333725e-06 5.60078443e-05 9.93299182e-06 ... 7.00564300e-08\n","   3.64687294e-05 9.71118861e-05]\n","  [2.88682600e-06 6.32814499e-06 9.26470148e-06 ... 2.21658141e-07\n","   1.02326499e-04 2.07625781e-04]\n","  [6.94723383e-07 5.36231369e-07 2.88456467e-05 ... 1.15467890e-06\n","   7.71207488e-06 5.08535686e-06]]\n","\n"," ...\n","\n"," [[2.47989851e-06 5.15093734e-06 1.34732827e-05 ... 1.37117768e-05\n","   2.86857858e-06 1.69707607e-06]\n","  [9.10692597e-06 3.05041776e-05 3.40788974e-04 ... 5.97550825e-04\n","   6.54773088e-04 2.52012615e-06]\n","  [2.62718440e-05 2.33747742e-05 1.43904443e-04 ... 4.37571493e-04\n","   5.72861580e-04 2.98143248e-03]\n","  ...\n","  [1.66971382e-04 1.53780289e-04 4.42508783e-04 ... 6.07324706e-04\n","   9.90770292e-04 1.19168672e-03]\n","  [4.22696976e-05 7.05207422e-05 4.99323651e-04 ... 6.60718477e-04\n","   1.20833609e-03 6.39091479e-04]\n","  [1.75092355e-05 9.06050191e-05 6.52785995e-04 ... 6.12863863e-04\n","   6.67420449e-04 3.31049996e-05]]\n","\n"," [[2.30598374e-07 4.77131493e-07 4.49444860e-06 ... 1.05063862e-06\n","   1.51505134e-07 1.80405081e-07]\n","  [1.45854017e-06 1.54996246e-06 2.83756272e-05 ... 9.41229155e-05\n","   1.31672678e-05 8.98712017e-07]\n","  [2.18918194e-06 2.83728703e-08 1.27449027e-07 ... 1.89619659e-05\n","   4.12949674e-07 1.81034538e-05]\n","  ...\n","  [2.97876850e-05 7.60674493e-06 2.49583309e-06 ... 3.42343151e-06\n","   2.42179274e-04 2.39587258e-04]\n","  [1.26346531e-05 2.12006125e-05 1.70408948e-05 ... 9.54497318e-06\n","   7.92805396e-04 8.71357915e-05]\n","  [4.16728881e-06 1.38405073e-06 2.73809601e-05 ... 2.03647432e-04\n","   9.26508292e-05 2.66869010e-05]]\n","\n"," [[3.65627488e-06 6.70381269e-06 2.24307551e-05 ... 1.46317889e-05\n","   1.72505770e-06 4.72434704e-06]\n","  [4.89353579e-06 2.05402976e-05 1.55581598e-04 ... 1.31485111e-03\n","   1.22977595e-03 7.75506578e-06]\n","  [2.97087045e-05 2.50965441e-05 8.06935423e-05 ... 6.91463822e-04\n","   1.68768247e-03 6.31509407e-04]\n","  ...\n","  [8.79920553e-04 5.00412891e-04 3.58865422e-04 ... 4.53632179e-04\n","   1.58764690e-03 1.25839619e-03]\n","  [4.14597453e-04 7.44537567e-04 6.31242234e-04 ... 2.32606078e-04\n","   4.61828575e-04 1.02522608e-03]\n","  [1.59892643e-05 1.82956690e-04 5.15450607e-04 ... 6.91357651e-04\n","   7.14383670e-04 7.69698163e-05]]]\n"]}],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","\n","from sklearn.metrics import accuracy_score, precision_score, recall_score\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras import layers, losses\n","from tensorflow.keras.datasets import fashion_mnist\n","from tensorflow.keras.models import Model\n","\n","(x_train, _), (x_test, _) = fashion_mnist.load_data()\n","\n","x_train = x_train.astype('float32') / 255.\n","x_test = x_test.astype('float32') / 255.\n","\n","print (x_train.shape)\n","print (x_test.shape)\n","\n","class Autoencoder(Model):\n","  def __init__(self, latent_dim, shape):\n","    super(Autoencoder, self).__init__()\n","    self.latent_dim = latent_dim\n","    self.shape = shape\n","    self.encoder = tf.keras.Sequential([\n","      layers.Flatten(),\n","      layers.Dense(latent_dim, activation='relu'),\n","    ])\n","    self.decoder = tf.keras.Sequential([\n","      layers.Dense(tf.math.reduce_prod(shape), activation='sigmoid'),\n","      layers.Reshape(shape)\n","    ])\n","\n","  def call(self, x):\n","    encoded = self.encoder(x)\n","    decoded = self.decoder(encoded)\n","    return decoded\n","\n","\n","shape = x_test.shape[1:]\n","latent_dim = 64\n","autoencoder = Autoencoder(latent_dim, shape)\n","\n","autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())\n","\n","autoencoder.fit(x_train, x_train,\n","                epochs=10,\n","                shuffle=True,\n","                validation_data=(x_test, x_test))\n","\n","encoded_imgs = autoencoder.encoder(x_test).numpy()\n","print(encoded_imgs)\n","decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()\n","print(decoded_imgs)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":51342,"status":"ok","timestamp":1710703293421,"user":{"displayName":"Hui Wen Nies","userId":"05887277120475105053"},"user_tz":-480},"id":"Gp19f-0J29V2","outputId":"419fc30a-0892-4a64-b3b3-472a7919b28e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 0s 0us/step\n","Epoch 1/10\n","235/235 [==============================] - 9s 32ms/step - loss: 0.2213 - val_loss: 0.1403\n","Epoch 2/10\n","235/235 [==============================] - 5s 21ms/step - loss: 0.1241 - val_loss: 0.1102\n","Epoch 3/10\n","235/235 [==============================] - 5s 20ms/step - loss: 0.1060 - val_loss: 0.0998\n","Epoch 4/10\n","235/235 [==============================] - 5s 20ms/step - loss: 0.0982 - val_loss: 0.0949\n","Epoch 5/10\n","235/235 [==============================] - 4s 17ms/step - loss: 0.0936 - val_loss: 0.0910\n","Epoch 6/10\n","235/235 [==============================] - 4s 19ms/step - loss: 0.0905 - val_loss: 0.0885\n","Epoch 7/10\n","235/235 [==============================] - 4s 16ms/step - loss: 0.0882 - val_loss: 0.0865\n","Epoch 8/10\n","235/235 [==============================] - 4s 16ms/step - loss: 0.0864 - val_loss: 0.0846\n","Epoch 9/10\n","235/235 [==============================] - 5s 20ms/step - loss: 0.0849 - val_loss: 0.0834\n","Epoch 10/10\n","235/235 [==============================] - 4s 16ms/step - loss: 0.0836 - val_loss: 0.0821\n","313/313 [==============================] - 1s 2ms/step\n"]}],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.layers import Input, Dense\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","\n","# Define the dimensions of the input data\n","input_dim = 784  # For MNIST dataset, each image is 28x28 pixels\n","\n","# Define the encoder model\n","encoder_input = Input(shape=(input_dim,))\n","encoder = Dense(128, activation='relu')(encoder_input)\n","encoder_output = Dense(64, activation='relu')(encoder)\n","\n","# Define the decoder model\n","decoder = Dense(128, activation='relu')(encoder_output)\n","decoder_output = Dense(input_dim, activation='sigmoid')(decoder)\n","\n","# Combine the encoder and decoder into the autoencoder model\n","autoencoder = Model(encoder_input, decoder_output)\n","\n","# Compile the autoencoder\n","autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy')\n","\n","# Load and preprocess the dataset (example: MNIST)\n","(X_train, _), (X_test, _) = tf.keras.datasets.mnist.load_data()\n","X_train = X_train.astype('float32') / 255.\n","X_test = X_test.astype('float32') / 255.\n","X_train = X_train.reshape((len(X_train), np.prod(X_train.shape[1:])))\n","X_test = X_test.reshape((len(X_test), np.prod(X_test.shape[1:])))\n","\n","# Train the autoencoder\n","autoencoder.fit(X_train, X_train, epochs=10, batch_size=256, shuffle=True, validation_data=(X_test, X_test))\n","\n","# Once trained, you can use the autoencoder for reconstruction\n","reconstructed_images = autoencoder.predict(X_test)\n"]},{"cell_type":"markdown","metadata":{"id":"qyEotYW6XuZU"},"source":["ANN"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2215,"status":"ok","timestamp":1710677604578,"user":{"displayName":"Hui Wen Nies","userId":"05887277120475105053"},"user_tz":-480},"id":"ko3Nd3llU8uc","outputId":"fc869a8e-7efc-4e6b-f9a4-a20cadfef332"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 1.0\n"]}],"source":["from sklearn.neural_network import MLPClassifier\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import accuracy_score\n","\n","# Load the Iris dataset\n","iris = load_iris()\n","X, y = iris.data, iris.target\n","\n","# Split the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Standardize the features\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# Define and train the ANN model\n","model = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', solver='adam', max_iter=1000, random_state=42)\n","model.fit(X_train_scaled, y_train)\n","\n","# Predict on the test set\n","y_pred = model.predict(X_test_scaled)\n","\n","# Calculate the accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy:\", accuracy)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45728,"status":"ok","timestamp":1710677770943,"user":{"displayName":"Hui Wen Nies","userId":"05887277120475105053"},"user_tz":-480},"id":"zikdRQOnVRFc","outputId":"7a7a4cb7-960a-418a-8b53-d3fe02aae339"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n","29515/29515 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n","26421880/26421880 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n","5148/5148 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n","4422102/4422102 [==============================] - 0s 0us/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 128)               100480    \n","                                                                 \n"," dropout (Dropout)           (None, 128)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 10)                1290      \n","                                                                 \n","=================================================================\n","Total params: 101770 (397.54 KB)\n","Trainable params: 101770 (397.54 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/10\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.5298 - sparse_categorical_accuracy: 0.8127\n","Epoch 2/10\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.4033 - sparse_categorical_accuracy: 0.8539\n","Epoch 3/10\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.3684 - sparse_categorical_accuracy: 0.8659\n","Epoch 4/10\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.3434 - sparse_categorical_accuracy: 0.8734\n","Epoch 5/10\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.3314 - sparse_categorical_accuracy: 0.8777\n","Epoch 6/10\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.3179 - sparse_categorical_accuracy: 0.8828\n","Epoch 7/10\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.3101 - sparse_categorical_accuracy: 0.8852\n","Epoch 8/10\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.2986 - sparse_categorical_accuracy: 0.8886\n","Epoch 9/10\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.2923 - sparse_categorical_accuracy: 0.8908\n","Epoch 10/10\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2840 - sparse_categorical_accuracy: 0.8941\n","313/313 [==============================] - 0s 1ms/step - loss: 0.3365 - sparse_categorical_accuracy: 0.8801\n","Test accuracy: 0.8801000118255615\n"]}],"source":["# Importing libraries\n","import numpy as np\n","import datetime\n","import tensorflow as tf\n","from tensorflow.keras.datasets import fashion_mnist\n","\n","# Loading the dataset\n","(X_train, y_train),(X_test, y_test)=fashion_mnist.load_data()\n","\n","# Normalizing the images\n","X_train=X_train/255\n","X_test=X_test/255\n","\n","# Reshaping the data\n","X_train.shape\n","X_train=X_train.reshape(-1,28*28)\n","X_train.shape\n","X_test=X_test.reshape(-1,28*28)\n","X_test.shape\n","\n","# 1. Defining the model\n","model=tf.keras.models.Sequential()\n","\n","# 2. Adding a first fully connected hidden layer\n","model.add(tf.keras.layers.Dense(units=128, activation='relu',input_shape=(784,)))\n","# number of units/neurons: 128\n","# activation function: ReLU\n","# input_shape: (784,)\n","\n","# 3. Adding second layer with dropout\n","model.add(tf.keras.layers.Dropout(0.2))\n","\n","# 4. Adding the output layer\n","model.add(tf.keras.layers.Dense(units=10, activation='softmax'))\n","# units: number of classes (10 in Fashion MNIST dataset)\n","# activation: softmax\n","\n","# 5. Compiling the model\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n","# Optimizer: Adam\n","# Loss: Sparse softmax (categorical) crossentropy\n","\n","model.summary()\n","\n","# 6. Training the model\n","model.fit(X_train, y_train, epochs=10)\n","\n","# 7. Model evaluation and prediction\n","test_loss, test_accuracy=model.evaluate(X_test, y_test)\n","print(\"Test accuracy: {}\".format(test_accuracy))\n","\n"]},{"cell_type":"markdown","metadata":{"id":"CzDpwtn-X-gg"},"source":["DNN"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21160,"status":"ok","timestamp":1710678379910,"user":{"displayName":"Hui Wen Nies","userId":"05887277120475105053"},"user_tz":-480},"id":"yPmE76HXYAB_","outputId":"e4137d1a-2c8b-42df-84ac-556663b5842a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 0s 0us/step\n","Epoch 1/5\n","1875/1875 [==============================] - 5s 2ms/step - loss: 0.2354 - accuracy: 0.9315\n","Epoch 2/5\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.0994 - accuracy: 0.9698\n","Epoch 3/5\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.0704 - accuracy: 0.9782\n","Epoch 4/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.0549 - accuracy: 0.9821\n","Epoch 5/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.0420 - accuracy: 0.9863\n","313/313 [==============================] - 0s 1ms/step - loss: 0.0908 - accuracy: 0.9732\n","Test accuracy: 0.9732000231742859\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","\n","# Define the architecture of the DNN\n","model = Sequential([\n","    Dense(128, activation='relu', input_shape=(784,)),  # Input layer with 128 neurons and ReLU activation\n","    Dense(64, activation='relu'),                       # Hidden layer with 64 neurons and ReLU activation\n","    Dense(10, activation='softmax')                     # Output layer with 10 neurons for classification (softmax activation)\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',   # Using cross-entropy loss for classification\n","              metrics=['accuracy'])\n","\n","# Load data (example: MNIST dataset)\n","mnist = tf.keras.datasets.mnist\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","\n","# Preprocess the data\n","x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to [0, 1]\n","\n","# Flatten the data\n","x_train_flattened = x_train.reshape(-1, 28*28)\n","x_test_flattened = x_test.reshape(-1, 28*28)\n","\n","# Train the model\n","model.fit(x_train_flattened, y_train, epochs=5)\n","\n","# Evaluate the model\n","test_loss, test_acc = model.evaluate(x_test_flattened, y_test)\n","print('Test accuracy:', test_acc)\n"]},{"cell_type":"markdown","metadata":{"id":"Z68TysDjYK-2"},"source":["CNN"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":151206,"status":"ok","timestamp":1710680560548,"user":{"displayName":"Hui Wen Nies","userId":"05887277120475105053"},"user_tz":-480},"id":"Zejg8yb2YMZv","outputId":"55fcefba-0749-4bb2-89b7-6fe1d97b0a5a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","1875/1875 [==============================] - 35s 19ms/step - loss: 0.2046 - accuracy: 0.9374\n","Epoch 2/5\n","1875/1875 [==============================] - 28s 15ms/step - loss: 0.0777 - accuracy: 0.9777\n","Epoch 3/5\n","1875/1875 [==============================] - 28s 15ms/step - loss: 0.0575 - accuracy: 0.9827\n","Epoch 4/5\n","1875/1875 [==============================] - 28s 15ms/step - loss: 0.0483 - accuracy: 0.9855\n","Epoch 5/5\n","1875/1875 [==============================] - 28s 15ms/step - loss: 0.0403 - accuracy: 0.9874\n","313/313 [==============================] - 2s 6ms/step - loss: 0.0258 - accuracy: 0.9917\n","Test accuracy: 0.9916999936103821\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","\n","# Define the architecture of the CNN model\n","model = Sequential([\n","    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),  # Convolutional layer with 32 filters of size 3x3 and ReLU activation\n","    MaxPooling2D((2, 2)),                                           # Max pooling layer with pool size 2x2\n","    Conv2D(64, (3, 3), activation='relu'),                          # Convolutional layer with 64 filters of size 3x3 and ReLU activation\n","    MaxPooling2D((2, 2)),                                           # Max pooling layer with pool size 2x2\n","    Flatten(),                                                       # Flatten layer to convert 2D feature maps to 1D\n","    Dense(128, activation='relu'),                                   # Fully connected layer with 128 neurons and ReLU activation\n","    Dropout(0.5),                                                    # Dropout layer with dropout rate 0.5 for regularization\n","    Dense(10, activation='softmax')                                  # Output layer with 10 neurons for classification (softmax activation)\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',   # Using cross-entropy loss for classification\n","              metrics=['accuracy'])\n","\n","# Load and preprocess the data (example: MNIST dataset)\n","mnist = tf.keras.datasets.mnist\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","\n","# Reshape and normalize the data\n","x_train = x_train.reshape(-1, 28, 28, 1) / 255.0\n","x_test = x_test.reshape(-1, 28, 28, 1) / 255.0\n","\n","# Train the model\n","model.fit(x_train, y_train, epochs=5)\n","\n","# Evaluate the model\n","test_loss, test_acc = model.evaluate(x_test, y_test)\n","print('Test accuracy:', test_acc)\n"]},{"cell_type":"markdown","metadata":{"id":"3ApKAb2uvNtz"},"source":["Deep Convolution Models"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":205192,"status":"ok","timestamp":1710684651163,"user":{"displayName":"Hui Wen Nies","userId":"05887277120475105053"},"user_tz":-480},"id":"4NGLpuSKvQoW","outputId":"92b63b2c-768e-4198-9cdb-2b29a439d37f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","1875/1875 [==============================] - 39s 20ms/step - loss: 0.2629 - accuracy: 0.9187\n","Epoch 2/5\n","1875/1875 [==============================] - 31s 17ms/step - loss: 0.0856 - accuracy: 0.9759\n","Epoch 3/5\n","1875/1875 [==============================] - 31s 16ms/step - loss: 0.0625 - accuracy: 0.9823\n","Epoch 4/5\n","1875/1875 [==============================] - 31s 16ms/step - loss: 0.0497 - accuracy: 0.9854\n","Epoch 5/5\n","1875/1875 [==============================] - 31s 16ms/step - loss: 0.0407 - accuracy: 0.9882\n","313/313 [==============================] - 2s 5ms/step - loss: 0.0478 - accuracy: 0.9856\n","Test accuracy: 0.9855999946594238\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","\n","# Define the architecture of the deep CNN model\n","model = Sequential([\n","    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),  # Convolutional layer with 32 filters of size 3x3 and ReLU activation\n","    MaxPooling2D((2, 2)),                                           # Max pooling layer with pool size 2x2\n","    Conv2D(64, (3, 3), activation='relu'),                          # Convolutional layer with 64 filters of size 3x3 and ReLU activation\n","    MaxPooling2D((2, 2)),                                           # Max pooling layer with pool size 2x2\n","    Conv2D(128, (3, 3), activation='relu'),                         # Convolutional layer with 128 filters of size 3x3 and ReLU activation\n","    MaxPooling2D((2, 2)),                                           # Max pooling layer with pool size 2x2\n","    Flatten(),                                                       # Flatten layer to convert 2D feature maps to 1D\n","    Dense(128, activation='relu'),                                   # Fully connected layer with 128 neurons and ReLU activation\n","    Dropout(0.5),                                                    # Dropout layer with dropout rate 0.5 for regularization\n","    Dense(10, activation='softmax')                                  # Output layer with 10 neurons for classification (softmax activation)\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',   # Using cross-entropy loss for classification\n","              metrics=['accuracy'])\n","\n","# Load and preprocess the data (example: MNIST dataset)\n","mnist = tf.keras.datasets.mnist\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","\n","# Reshape and normalize the data\n","x_train = x_train.reshape(-1, 28, 28, 1) / 255.0\n","x_test = x_test.reshape(-1, 28, 28, 1) / 255.0\n","\n","# Train the model\n","model.fit(x_train, y_train, epochs=5)\n","\n","# Evaluate the model\n","test_loss, test_acc = model.evaluate(x_test, y_test)\n","print('Test accuracy:', test_acc)\n"]},{"cell_type":"markdown","metadata":{"id":"-PI6lYf_Yslv"},"source":["RNN"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7064,"status":"ok","timestamp":1710700297960,"user":{"displayName":"Hui Wen Nies","userId":"05887277120475105053"},"user_tz":-480},"id":"hNPbO3lZYtwd","outputId":"78be66a2-47a6-41ea-be59-c2480f601b7c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, None, 64)          64000     \n","                                                                 \n"," lstm (LSTM)                 (None, 128)               98816     \n","                                                                 \n"," dense (Dense)               (None, 10)                1290      \n","                                                                 \n","=================================================================\n","Total params: 164106 (641.04 KB)\n","Trainable params: 164106 (641.04 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["import numpy as np\n","import tensorflow as tf\n","import keras\n","from keras import layers\n","\n","model = keras.Sequential()\n","# Add an Embedding layer expecting input vocab of size 1000, and\n","# output embedding dimension of size 64.\n","model.add(layers.Embedding(input_dim=1000, output_dim=64))\n","\n","# Add a LSTM layer with 128 internal units.\n","model.add(layers.LSTM(128))\n","\n","# Add a Dense layer with 10 units.\n","model.add(layers.Dense(10))\n","\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":921,"status":"ok","timestamp":1710700402349,"user":{"displayName":"Hui Wen Nies","userId":"05887277120475105053"},"user_tz":-480},"id":"EX9S86zusDYm","outputId":"a039742b-0e5d-4682-8a39-21c017e12ae4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_1 (Embedding)     (None, None, 64)          64000     \n","                                                                 \n"," gru (GRU)                   (None, None, 256)         247296    \n","                                                                 \n"," simple_rnn (SimpleRNN)      (None, 128)               49280     \n","                                                                 \n"," dense_1 (Dense)             (None, 10)                1290      \n","                                                                 \n","=================================================================\n","Total params: 361866 (1.38 MB)\n","Trainable params: 361866 (1.38 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["model = keras.Sequential()\n","model.add(layers.Embedding(input_dim=1000, output_dim=64))\n","\n","# The output of GRU will be a 3D tensor of shape (batch_size, timesteps, 256)\n","model.add(layers.GRU(256, return_sequences=True))\n","\n","# The output of SimpleRNN will be a 2D tensor of shape (batch_size, 128)\n","model.add(layers.SimpleRNN(128))\n","\n","model.add(layers.Dense(10))\n","\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3265,"status":"ok","timestamp":1710700663719,"user":{"displayName":"Hui Wen Nies","userId":"05887277120475105053"},"user_tz":-480},"id":"uKfkChtGtGH4","outputId":"582c667f-30ea-48df-f60a-ec403730cc5e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","4/4 [==============================] - 2s 8ms/step - loss: 0.6963 - accuracy: 0.5100\n","Epoch 2/10\n","4/4 [==============================] - 0s 6ms/step - loss: 0.6676 - accuracy: 0.6200\n","Epoch 3/10\n","4/4 [==============================] - 0s 7ms/step - loss: 0.6501 - accuracy: 0.6300\n","Epoch 4/10\n","4/4 [==============================] - 0s 7ms/step - loss: 0.6384 - accuracy: 0.6000\n","Epoch 5/10\n","4/4 [==============================] - 0s 5ms/step - loss: 0.6289 - accuracy: 0.6100\n","Epoch 6/10\n","4/4 [==============================] - 0s 5ms/step - loss: 0.6235 - accuracy: 0.6300\n","Epoch 7/10\n","4/4 [==============================] - 0s 5ms/step - loss: 0.6178 - accuracy: 0.6700\n","Epoch 8/10\n","4/4 [==============================] - 0s 7ms/step - loss: 0.6157 - accuracy: 0.6500\n","Epoch 9/10\n","4/4 [==============================] - 0s 7ms/step - loss: 0.6126 - accuracy: 0.6300\n","Epoch 10/10\n","4/4 [==============================] - 0s 5ms/step - loss: 0.6099 - accuracy: 0.6300\n"]},{"data":{"text/plain":["<keras.src.callbacks.History at 0x7e4f3c83cd90>"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["import numpy as np\n","import tensorflow as tf\n","\n","# Define the sequence length and number of features\n","sequence_length = 10\n","num_features = 1  # For simplicity, let's assume each element in the sequence is a single feature\n","\n","# Generate some sample sequential data\n","X_train = np.random.randn(100, sequence_length, num_features)\n","y_train = np.random.randint(0, 2, size=(100,))  # Binary classification task, random labels for demonstration\n","\n","# Define the RNN model\n","model = tf.keras.Sequential([\n","    tf.keras.layers.SimpleRNN(32, input_shape=(sequence_length, num_features)),\n","    tf.keras.layers.Dense(1, activation='sigmoid')  # Binary classification output\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","model.fit(X_train, y_train, epochs=10, batch_size=32)\n","\n","# Once trained, you can use the model for predictions\n","# For example:\n","# predictions = model.predict(X_test)\n"]},{"cell_type":"markdown","metadata":{"id":"JwNd4Qcz0Ylx"},"source":["GAN"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14895,"status":"ok","timestamp":1710702582424,"user":{"displayName":"Hui Wen Nies","userId":"05887277120475105053"},"user_tz":-480},"id":"IARFP0dh0XHi","outputId":"7157ecc3-06d7-4623-f693-0c485418d609"},"outputs":[{"name":"stdout","output_type":"stream","text":["2/2 [==============================] - 0s 8ms/step\n","Epoch 1/100, Discriminator Loss: 0.9757413268089294, Generator Loss: 0.8630276322364807\n","2/2 [==============================] - 0s 7ms/step\n","Epoch 2/100, Discriminator Loss: 0.8138350546360016, Generator Loss: 1.2077594995498657\n","2/2 [==============================] - 0s 7ms/step\n","Epoch 3/100, Discriminator Loss: 0.7855572402477264, Generator Loss: 1.606438159942627\n","2/2 [==============================] - 0s 6ms/step\n","Epoch 4/100, Discriminator Loss: 0.7415286898612976, Generator Loss: 2.0155181884765625\n","2/2 [==============================] - 0s 6ms/step\n","Epoch 5/100, Discriminator Loss: 0.7305880859494209, Generator Loss: 2.4154045581817627\n","2/2 [==============================] - 0s 8ms/step\n","Epoch 6/100, Discriminator Loss: 0.6771730482578278, Generator Loss: 2.747612237930298\n","2/2 [==============================] - 0s 8ms/step\n","Epoch 7/100, Discriminator Loss: 0.6634741984307766, Generator Loss: 3.031863212585449\n","2/2 [==============================] - 0s 9ms/step\n","Epoch 8/100, Discriminator Loss: 0.6569011360406876, Generator Loss: 3.2804172039031982\n","2/2 [==============================] - 0s 5ms/step\n","Epoch 9/100, Discriminator Loss: 0.6302485298365355, Generator Loss: 3.491830587387085\n","2/2 [==============================] - 0s 10ms/step\n","Epoch 10/100, Discriminator Loss: 0.5600013472139835, Generator Loss: 3.6348178386688232\n","2/2 [==============================] - 0s 11ms/step\n","Epoch 11/100, Discriminator Loss: 0.6494760103523731, Generator Loss: 3.7945902347564697\n","2/2 [==============================] - 0s 6ms/step\n","Epoch 12/100, Discriminator Loss: 0.6530876476317644, Generator Loss: 3.88459849357605\n","2/2 [==============================] - 0s 5ms/step\n","Epoch 13/100, Discriminator Loss: 0.5376379266381264, Generator Loss: 3.983006000518799\n","2/2 [==============================] - 0s 7ms/step\n","Epoch 14/100, Discriminator Loss: 0.622345307841897, Generator Loss: 4.036371231079102\n","2/2 [==============================] - 0s 6ms/step\n","Epoch 15/100, Discriminator Loss: 0.5712632872164249, Generator Loss: 4.102425575256348\n","2/2 [==============================] - 0s 7ms/step\n","Epoch 16/100, Discriminator Loss: 0.5231911540031433, Generator Loss: 4.116600036621094\n","2/2 [==============================] - 0s 5ms/step\n","Epoch 17/100, Discriminator Loss: 0.46850907523185015, Generator Loss: 4.149664878845215\n","2/2 [==============================] - 0s 6ms/step\n","Epoch 18/100, Discriminator Loss: 0.5989111308008432, Generator Loss: 4.157070159912109\n","2/2 [==============================] - 0s 8ms/step\n","Epoch 19/100, Discriminator Loss: 0.49527259077876806, Generator Loss: 4.1621832847595215\n","2/2 [==============================] - 0s 6ms/step\n","Epoch 20/100, Discriminator Loss: 0.4886405849829316, Generator Loss: 4.152390003204346\n","2/2 [==============================] - 0s 6ms/step\n","Epoch 21/100, Discriminator Loss: 0.5143090207129717, Generator Loss: 4.160930633544922\n","2/2 [==============================] - 0s 5ms/step\n","Epoch 22/100, Discriminator Loss: 0.517249240539968, Generator Loss: 4.1347503662109375\n","2/2 [==============================] - 0s 6ms/step\n","Epoch 23/100, Discriminator Loss: 0.5383378770202398, Generator Loss: 4.102352142333984\n","2/2 [==============================] - 0s 5ms/step\n","Epoch 24/100, Discriminator Loss: 0.4564539473503828, Generator Loss: 4.140873908996582\n","2/2 [==============================] - 0s 5ms/step\n","Epoch 25/100, Discriminator Loss: 0.4784127678722143, Generator Loss: 4.097415924072266\n","2/2 [==============================] - 0s 5ms/step\n","Epoch 26/100, Discriminator Loss: 0.4601468201726675, Generator Loss: 4.048398017883301\n","2/2 [==============================] - 0s 7ms/step\n","Epoch 27/100, Discriminator Loss: 0.5102094523608685, Generator Loss: 4.0572614669799805\n","2/2 [==============================] - 0s 6ms/step\n","Epoch 28/100, Discriminator Loss: 0.43784449994564056, Generator Loss: 4.032214641571045\n","2/2 [==============================] - 0s 5ms/step\n","Epoch 29/100, Discriminator Loss: 0.4815988037735224, Generator Loss: 4.013622760772705\n","2/2 [==============================] - 0s 5ms/step\n","Epoch 30/100, Discriminator Loss: 0.45017003268003464, Generator Loss: 4.0006327629089355\n","2/2 [==============================] - 0s 5ms/step\n","Epoch 31/100, Discriminator Loss: 0.4151734299957752, Generator Loss: 4.0194807052612305\n","2/2 [==============================] - 0s 6ms/step\n","Epoch 32/100, Discriminator Loss: 0.46660691499710083, Generator Loss: 3.9962410926818848\n","2/2 [==============================] - 0s 6ms/step\n","Epoch 33/100, Discriminator Loss: 0.41800981387495995, Generator Loss: 3.941702365875244\n","2/2 [==============================] - 0s 6ms/step\n","Epoch 34/100, Discriminator Loss: 0.44281194917857647, Generator Loss: 3.9498143196105957\n","2/2 [==============================] - 0s 6ms/step\n","Epoch 35/100, Discriminator Loss: 0.4285560678690672, Generator Loss: 3.931495189666748\n","2/2 [==============================] - 0s 6ms/step\n","Epoch 36/100, Discriminator Loss: 0.4415534008294344, Generator Loss: 3.906320571899414\n","2/2 [==============================] - 0s 7ms/step\n","Epoch 37/100, Discriminator Loss: 0.44869086146354675, Generator Loss: 3.8653712272644043\n","2/2 [==============================] - 0s 6ms/step\n","Epoch 38/100, Discriminator Loss: 0.45601249020546675, Generator Loss: 3.8474326133728027\n","2/2 [==============================] - 0s 5ms/step\n","Epoch 39/100, Discriminator Loss: 0.38383893854916096, Generator Loss: 3.82672119140625\n","2/2 [==============================] - 0s 5ms/step\n","Epoch 40/100, Discriminator Loss: 0.3856929987668991, Generator Loss: 3.8228323459625244\n","2/2 [==============================] - 0s 5ms/step\n","Epoch 41/100, Discriminator Loss: 0.3809556383639574, Generator Loss: 3.8147497177124023\n","2/2 [==============================] - 0s 6ms/step\n","Epoch 42/100, Discriminator Loss: 0.4530376186594367, Generator Loss: 3.7867584228515625\n","2/2 [==============================] - 0s 5ms/step\n","Epoch 43/100, Discriminator Loss: 0.3792545599862933, Generator Loss: 3.759026050567627\n","2/2 [==============================] - 0s 6ms/step\n","Epoch 44/100, Discriminator Loss: 0.3623574785888195, Generator Loss: 3.7798619270324707\n","2/2 [==============================] - 0s 5ms/step\n","Epoch 45/100, Discriminator Loss: 0.3440571576356888, Generator Loss: 3.744999885559082\n","2/2 [==============================] - 0s 5ms/step\n","Epoch 46/100, Discriminator Loss: 0.4016872141510248, Generator Loss: 3.747368574142456\n","2/2 [==============================] - 0s 5ms/step\n","Epoch 47/100, Discriminator Loss: 0.3721812414005399, Generator Loss: 3.7834842205047607\n","2/2 [==============================] - 0s 6ms/step\n","Epoch 48/100, Discriminator Loss: 0.33600868470966816, Generator Loss: 3.7166528701782227\n","2/2 [==============================] - 0s 6ms/step\n","Epoch 49/100, Discriminator Loss: 0.30531252454966307, Generator Loss: 3.687803268432617\n","2/2 [==============================] - 0s 5ms/step\n","Epoch 50/100, Discriminator Loss: 0.3876145286485553, Generator Loss: 3.7210919857025146\n","2/2 [==============================] - 0s 7ms/step\n","Epoch 51/100, Discriminator Loss: 0.3777419487014413, Generator Loss: 3.7215514183044434\n","2/2 [==============================] - 0s 5ms/step\n","Epoch 52/100, Discriminator Loss: 0.34204015508294106, Generator Loss: 3.688495635986328\n","2/2 [==============================] - 0s 6ms/step\n","Epoch 53/100, Discriminator Loss: 0.40606644097715616, Generator Loss: 3.7107396125793457\n","2/2 [==============================] - 0s 6ms/step\n","Epoch 54/100, Discriminator Loss: 0.3165096417069435, Generator Loss: 3.716157913208008\n","2/2 [==============================] - 0s 6ms/step\n","Epoch 55/100, Discriminator Loss: 0.37853914499282837, Generator Loss: 3.749936103820801\n","2/2 [==============================] - 0s 5ms/step\n","Epoch 56/100, Discriminator Loss: 0.35038221813738346, Generator Loss: 3.679701089859009\n","2/2 [==============================] - 0s 6ms/step\n","Epoch 57/100, Discriminator Loss: 0.341961320489645, Generator Loss: 3.6679320335388184\n","2/2 [==============================] - 0s 5ms/step\n","Epoch 58/100, Discriminator Loss: 0.30286514945328236, Generator Loss: 3.672800064086914\n","2/2 [==============================] - 0s 9ms/step\n","Epoch 59/100, Discriminator Loss: 0.3061750456690788, Generator Loss: 3.7108120918273926\n","2/2 [==============================] - 0s 7ms/step\n","Epoch 60/100, Discriminator Loss: 0.2915391456335783, Generator Loss: 3.7098710536956787\n","2/2 [==============================] - 0s 5ms/step\n","Epoch 61/100, Discriminator Loss: 0.3416128661483526, Generator Loss: 3.6914100646972656\n","2/2 [==============================] - 0s 6ms/step\n","Epoch 62/100, Discriminator Loss: 0.2770033534616232, Generator Loss: 3.6696128845214844\n","2/2 [==============================] - 0s 5ms/step\n","Epoch 63/100, Discriminator Loss: 0.2884912732988596, Generator Loss: 3.739440679550171\n","2/2 [==============================] - 0s 5ms/step\n","Epoch 64/100, Discriminator Loss: 0.3087727874517441, Generator Loss: 3.74741792678833\n","2/2 [==============================] - 0s 5ms/step\n","Epoch 65/100, Discriminator Loss: 0.2774932440370321, Generator Loss: 3.76776123046875\n","2/2 [==============================] - 0s 5ms/step\n","Epoch 66/100, Discriminator Loss: 0.30908612068742514, Generator Loss: 3.791208267211914\n","2/2 [==============================] - 0s 7ms/step\n","Epoch 67/100, Discriminator Loss: 0.32206854969263077, Generator Loss: 3.791954755783081\n","2/2 [==============================] - 0s 5ms/step\n","Epoch 68/100, Discriminator Loss: 0.2874089339748025, Generator Loss: 3.760650157928467\n","2/2 [==============================] - 0s 7ms/step\n","Epoch 69/100, Discriminator Loss: 0.3008708478882909, Generator Loss: 3.7513647079467773\n","2/2 [==============================] - 0s 7ms/step\n","Epoch 70/100, Discriminator Loss: 0.2580044437199831, Generator Loss: 3.8244991302490234\n","2/2 [==============================] - 0s 6ms/step\n","Epoch 71/100, Discriminator Loss: 0.2707118894904852, Generator Loss: 3.722940444946289\n","2/2 [==============================] - 0s 7ms/step\n","Epoch 72/100, Discriminator Loss: 0.24238906614482403, Generator Loss: 3.806349277496338\n","2/2 [==============================] - 0s 6ms/step\n","Epoch 73/100, Discriminator Loss: 0.2828187569975853, Generator Loss: 3.835538387298584\n","2/2 [==============================] - 0s 6ms/step\n","Epoch 74/100, Discriminator Loss: 0.2471405752003193, Generator Loss: 3.7985761165618896\n","2/2 [==============================] - 0s 6ms/step\n","Epoch 75/100, Discriminator Loss: 0.22035535611212254, Generator Loss: 3.7275872230529785\n","2/2 [==============================] - 0s 6ms/step\n","Epoch 76/100, Discriminator Loss: 0.28448432218283415, Generator Loss: 3.8126564025878906\n","2/2 [==============================] - 0s 5ms/step\n","Epoch 77/100, Discriminator Loss: 0.232591082341969, Generator Loss: 3.760758399963379\n","2/2 [==============================] - 0s 7ms/step\n","Epoch 78/100, Discriminator Loss: 0.24757694266736507, Generator Loss: 3.7830677032470703\n","2/2 [==============================] - 0s 5ms/step\n","Epoch 79/100, Discriminator Loss: 0.22016130201518536, Generator Loss: 3.843916416168213\n","2/2 [==============================] - 0s 6ms/step\n","Epoch 80/100, Discriminator Loss: 0.2285857442766428, Generator Loss: 3.7994680404663086\n","2/2 [==============================] - 0s 9ms/step\n","Epoch 81/100, Discriminator Loss: 0.24120893143117428, Generator Loss: 3.797482967376709\n","2/2 [==============================] - 0s 5ms/step\n","Epoch 82/100, Discriminator Loss: 0.2378076519817114, Generator Loss: 3.9184093475341797\n","2/2 [==============================] - 0s 6ms/step\n","Epoch 83/100, Discriminator Loss: 0.26628320198506117, Generator Loss: 3.8975937366485596\n","2/2 [==============================] - 0s 5ms/step\n","Epoch 84/100, Discriminator Loss: 0.24595190677791834, Generator Loss: 3.871826648712158\n","2/2 [==============================] - 0s 5ms/step\n","Epoch 85/100, Discriminator Loss: 0.2028120458126068, Generator Loss: 3.751477003097534\n","2/2 [==============================] - 0s 6ms/step\n","Epoch 86/100, Discriminator Loss: 0.20294681750237942, Generator Loss: 3.885305404663086\n","2/2 [==============================] - 0s 4ms/step\n","Epoch 87/100, Discriminator Loss: 0.22835475951433182, Generator Loss: 3.915651559829712\n","2/2 [==============================] - 0s 5ms/step\n","Epoch 88/100, Discriminator Loss: 0.2372918426990509, Generator Loss: 3.9115748405456543\n","2/2 [==============================] - 0s 4ms/step\n","Epoch 89/100, Discriminator Loss: 0.2415522336959839, Generator Loss: 3.7972195148468018\n","2/2 [==============================] - 0s 6ms/step\n","Epoch 90/100, Discriminator Loss: 0.2105665635317564, Generator Loss: 3.868063449859619\n","2/2 [==============================] - 0s 5ms/step\n","Epoch 91/100, Discriminator Loss: 0.2183542400598526, Generator Loss: 4.034156799316406\n","2/2 [==============================] - 0s 6ms/step\n","Epoch 92/100, Discriminator Loss: 0.2302738567814231, Generator Loss: 3.9310214519500732\n","2/2 [==============================] - 0s 7ms/step\n","Epoch 93/100, Discriminator Loss: 0.24773996509611607, Generator Loss: 3.904756784439087\n","2/2 [==============================] - 0s 8ms/step\n","Epoch 94/100, Discriminator Loss: 0.18149712309241295, Generator Loss: 3.9487316608428955\n","2/2 [==============================] - 0s 5ms/step\n","Epoch 95/100, Discriminator Loss: 0.20651305466890335, Generator Loss: 3.9761672019958496\n","2/2 [==============================] - 0s 5ms/step\n","Epoch 96/100, Discriminator Loss: 0.21209795773029327, Generator Loss: 3.9621636867523193\n","2/2 [==============================] - 0s 8ms/step\n","Epoch 97/100, Discriminator Loss: 0.18291697185486555, Generator Loss: 3.8928918838500977\n","2/2 [==============================] - 0s 8ms/step\n","Epoch 98/100, Discriminator Loss: 0.19346335623413324, Generator Loss: 4.018774032592773\n","2/2 [==============================] - 0s 5ms/step\n","Epoch 99/100, Discriminator Loss: 0.18623567838221788, Generator Loss: 4.000369071960449\n","2/2 [==============================] - 0s 5ms/step\n","Epoch 100/100, Discriminator Loss: 0.1986838160082698, Generator Loss: 4.107605934143066\n"]}],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.layers import Dense, Flatten, Reshape\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.optimizers import Adam\n","\n","# Define the dimensions of the latent space (input to the generator)\n","latent_dim = 100\n","\n","# Define the generator model\n","generator = Sequential([\n","    Dense(128, input_dim=latent_dim, activation='relu'),\n","    Dense(784, activation='sigmoid'),\n","    Reshape((28, 28))\n","])\n","\n","# Define the discriminator model\n","discriminator = Sequential([\n","    Flatten(input_shape=(28, 28)),\n","    Dense(128, activation='relu'),\n","    Dense(1, activation='sigmoid')\n","])\n","\n","# Compile the discriminator (binary crossentropy loss)\n","discriminator.compile(optimizer=Adam(learning_rate=0.0002), loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Freeze the discriminator during the combined model training\n","discriminator.trainable = False\n","\n","# Define the combined model (GAN)\n","gan = Sequential([generator, discriminator])\n","\n","# Compile the GAN (binary crossentropy loss)\n","gan.compile(optimizer=Adam(learning_rate=0.0002), loss='binary_crossentropy')\n","\n","# Function to generate random noise (latent points)\n","def generate_latent_points(latent_dim, n_samples):\n","    return np.random.randn(n_samples, latent_dim)\n","\n","# Function to generate fake images using the generator\n","def generate_fake_samples(generator, latent_dim, n_samples):\n","    latent_points = generate_latent_points(latent_dim, n_samples)\n","    return generator.predict(latent_points)\n","\n","# Function to train the GAN\n","def train_gan(gan, generator, discriminator, latent_dim, n_epochs=100, batch_size=128):\n","    half_batch = batch_size // 2\n","    for epoch in range(n_epochs):\n","        # Train the discriminator\n","        real_images = np.random.randn(half_batch, 28, 28)\n","        real_labels = np.ones((half_batch, 1))\n","        fake_images = generate_fake_samples(generator, latent_dim, half_batch)\n","        fake_labels = np.zeros((half_batch, 1))\n","        discriminator_loss_real = discriminator.train_on_batch(real_images, real_labels)\n","        discriminator_loss_fake = discriminator.train_on_batch(fake_images, fake_labels)\n","        discriminator_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_fake)\n","        # Train the generator (via the combined GAN model)\n","        latent_points = generate_latent_points(latent_dim, batch_size)\n","        misleading_targets = np.ones((batch_size, 1))\n","        gan_loss = gan.train_on_batch(latent_points, misleading_targets)\n","        # Print progress\n","        print(f\"Epoch {epoch+1}/{n_epochs}, Discriminator Loss: {discriminator_loss[0]}, Generator Loss: {gan_loss}\")\n","\n","# Train the GAN\n","train_gan(gan, generator, discriminator, latent_dim)\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyN60Ifsiz81pDYsBZnHcMly","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":0}
